{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GriPet12/mercorAiDetect/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koGQ4Y-lGZLG"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece transformers --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "a0uQ84jN9qOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xeTebSACxfe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "oEQc0iyc9yst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "train['answer'] = train['answer'].astype(str)\n",
        "train['topic'] = train['topic'].astype(str)\n",
        "test['answer'] = test['answer'].astype(str)\n",
        "test['topic'] = test['topic'].astype(str)"
      ],
      "metadata": {
        "id": "WQ5mOMGY9mf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class"
      ],
      "metadata": {
        "id": "_KBXwKgY_SPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, topics, answers, labels=None):\n",
        "        self.texts = [t + \" [SEP] \" + a for t, a in zip(topics, answers)]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encodings = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item"
      ],
      "metadata": {
        "id": "1rNKmrDz_PkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "XPanA8iG_l_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "OUTPUT_DIR = \"./deberta_v3_fulltrain\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 50\n",
        "LR = 5e-7\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zC1V4fG__kEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "U8ubvCcF_8KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "ucUJt4oP_6aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Datasets"
      ],
      "metadata": {
        "id": "LJ_YR80yAQLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(train['topic'].tolist(), train['answer'].tolist(), train['is_cheating'].tolist())\n",
        "test_dataset = TextDataset(test['topic'].tolist(), test['answer'].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "fsHOxUBUAPCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model, Optimizer, Loss"
      ],
      "metadata": {
        "id": "tQCQCqTEAqOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "L7NgeVf5AsEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "DmlfVCrbBE_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device).unsqueeze(1)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss\n",
        "\n",
        "        progress_bar.set_postfix({'loss': f'{current_loss:.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} done. Average Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "final_model_path = os.path.join(OUTPUT_DIR, \"final_model.pth\")\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"âœ… Final model saved to {final_model_path}\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS + 1), train_losses, marker='o', label='Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plot_path = os.path.join(OUTPUT_DIR, \"loss_plot.png\")\n",
        "plt.savefig(plot_path)\n",
        "print(f\"ðŸ“Š Loss plot saved to {plot_path}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mh6d0OcuBHl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Predictions"
      ],
      "metadata": {
        "id": "p845wA4hBHEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Predicting on test set\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "        test_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "\n",
        "test_preds = np.array(test_preds).flatten()"
      ],
      "metadata": {
        "id": "kLu4Khk3-ZHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10APaeiOOYqeJ_N-Atd4LO8qPinfSbxKZ",
      "authorship_tag": "ABX9TyOzBDP7Pl0o7u8Hv6Ihwfqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}