{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GriPet12/mercorAiDetect/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "koGQ4Y-lGZLG"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece transformers --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "a0uQ84jN9qOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2xeTebSACxfe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "oEQc0iyc9yst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "train['answer'] = train['answer'].astype(str)\n",
        "train['topic'] = train['topic'].astype(str)\n",
        "test['answer'] = test['answer'].astype(str)\n",
        "test['topic'] = test['topic'].astype(str)"
      ],
      "metadata": {
        "id": "WQ5mOMGY9mf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class"
      ],
      "metadata": {
        "id": "_KBXwKgY_SPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, topics, answers, labels=None):\n",
        "        self.texts = [t + \" [SEP] \" + a for t, a in zip(topics, answers)]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encodings = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item"
      ],
      "metadata": {
        "id": "1rNKmrDz_PkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "XPanA8iG_l_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "OUTPUT_DIR = \"./deberta_v3_fulltrain\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 50\n",
        "LR = 5e-7\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zC1V4fG__kEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "U8ubvCcF_8KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "ucUJt4oP_6aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLu4Khk3-ZHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "10APaeiOOYqeJ_N-Atd4LO8qPinfSbxKZ",
      "authorship_tag": "ABX9TyM4onh4xt6FhgZMGdXJNjUt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}